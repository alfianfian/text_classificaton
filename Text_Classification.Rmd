---
title: "Text_Classification"
author: "Alfiansyah Prasetyo Nugroho"
date: "2022-12-02"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load}
library(dplyr)
library(SnowballC)
library(tidytext)
library(tm)
library(readr)
library(caret)
library(naivebayes)
library(e1071)
library(randomForest)
```
```{r import_data}
df <- read.csv("C:/Users/LENOVO/Downloads/text Classification/SPAM text message 20170820 - Data.csv")
head(df)
df_copy <- df
df_copy$Category <- as.factor(df_copy$Category)
df$Doc <- seq(1:nrow(df))
```
```{r preprocessing}
# pre-processing
# merubah teks ke bentuk lower case
df_copy$Message <- tolower(df_copy$Message)
#menghapus tanda baca (punctuation)
df_copy$Message <- gsub(pattern = "[[:punct:]]", replacement = "", df_copy$Message)
# menghapus angka
df_copy$Message <- gsub(pattern = "[[:digit:]]", replacement = "", df_copy$Message)
# menghapus special character -> (^) <- untuk sebagai pengecualian
df_copy$Message <- gsub(pattern = "[^[:alnum:]]", replacement = " ", df_copy$Message)
# tokenisasi
df_token <- df_copy
df_token$Doc <- seq(1:nrow(df_token))
df_token <- df_token[,-1]
df_token <- as_tibble(df_token)
df_tfidf <- df_token %>%
  unnest_tokens(output = word, Message, token = "words") %>%
  mutate(stem = wordStem(word)) %>%
  anti_join(stop_words) %>%
  count(Doc, word) %>%
  bind_tf_idf(word, Doc, n)
```
```{r preprocessing_lanjutan}
df_dtm <- df_tfidf %>%
  cast_dtm(Doc, word, tf_idf)
df_dtm <- removeSparseTerms(df_dtm, 0.98)
df_dtm$dimnames
df_dtm2 <- data.frame(as.matrix(df_dtm))
df_dtm2$Doc <- as.numeric(as.numeric(row.names(df_dtm2)))
# merge dataframe
df_merge <- (merge.data.frame(x = df_dtm2, y = df, by.y = "Doc"))
df_merge$Category <- as.factor(df_merge$Category)
df_merge <- df_merge[,-c(1,26)] # Menghilangkan doc
```
```{r pemodelan}
# pemodelan
# Membagi data ke dalam training dan testing
# 80:20, 60:40, 70:30, 90:10 -> RANDOM SAMPLING
table(df_merge$Category)[2]/sum(table(df_merge$Category))
library(caret)
train_index <- createDataPartition(df_merge$Category, p=0.8, list=F)
train <- df_merge[train_index,]
test <- df_merge[-train_index,]
table(test$Category)
149/(944+149)
```
```{r model_training}
# Melatih Model
# Naive Bayes
model_nbc <- naiveBayes(Category~., data=train)
# Random Forest
model_rf <- randomForest(Category~., data=train)
```
```{r model_traing_evaluation}
# Evaluasi Model Training
fitted_values_nbc <- predict(model_nbc, train)
fitted_values_rf <- model_rf$predicted

confusionMatrix(fitted_values_nbc, train$Category) #Model NBC = 30%
confusionMatrix(fitted_values_rf, train$Category) #Model RF = 95%
```
```{r model_testing_evaluation}
# Evaluasi Model Testing
pred_nbc <- predict(model_nbc, test, type = "class")
pred_rf <- predict(model_rf, test)

confusionMatrix(pred_nbc, test$Category) #Model NBC = 30%
confusionMatrix(pred_rf, test$Category) #Model RF = 95%
```
